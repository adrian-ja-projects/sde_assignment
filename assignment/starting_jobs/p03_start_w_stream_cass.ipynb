{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author: Adrian J\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import TimestampType, DateType, IntegerType, StringType\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get or create spark delta session\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local\")\n",
    "    .appName(\"p0_stream_triggers\")\n",
    "    .config(\"spark.cassandra.connection.host\", \"dockertests-cassandra-1\")\n",
    "    .config(\"spark.cassandra.auth.username\", \"cassandra\")\n",
    "    .config(\"spark.cassandra.auth.password\", \"cassandra\")\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source table in raw zone\n",
    "source_schema = 'assignment_data'\n",
    "source_table_name = 'r_session_events'\n",
    "source_dl_raw_path = f'/home/jovyan/work/data_lake/raw/{source_schema}/{source_table_name}/'\n",
    "\n",
    "#delta sink table uc zone\n",
    "sink_dl_schema = 'uc_assignment'\n",
    "sink_table_name = 'uc_delta_session_events'\n",
    "sink_dl_uc_path = f'/home/jovyan/work/data_lake/use_case/{sink_dl_schema}/{sink_table_name}'\n",
    "\n",
    "#assuming finland time is the default time for the data lake ts\n",
    "FinlandTimeZone = pytz.timezone('Europe/Helsinki')\n",
    "#all columns from source\n",
    "source_select_columns = [\"country\", \"player_id\", \"session_id\", \"ts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ START events and WRITE to cassandra\n",
    "def start_events_write_to_cassandra(microbatch_input, epoch_id):\n",
    "    (microbatch_input\n",
    "     .write\n",
    "     .format(\"org.apache.spark.sql.cassandra\")\n",
    "     .option(\"keyspace\", \"session_events\")\n",
    "     .option(\"table\", \"api_start_session_by_hour\")\n",
    "     .mode(\"append\")\n",
    "     .save())\n",
    "    #microbatch_input.show(truncate=False)\n",
    "\n",
    "#START WRITE to cassandra\n",
    "strm_start_events_append_cassandra = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"delta\")\n",
    "    .load(source_dl_raw_path)\n",
    "    .where(F.col(\"event\")==\"start\")\n",
    "    .select(F.col(\"ts\").cast(DateType()).cast(StringType()).alias(\"event_date\"),\n",
    "            F.col(\"country\"),\n",
    "            F.lit(datetime.now(FinlandTimeZone).strftime('%Y-%m-%d %H:%M:%S')).cast(TimestampType()).alias(\"cs_insert_ts\"),\n",
    "            F.col(\"player_id\"),\n",
    "            F.col(\"session_id\"),\n",
    "            F.col(\"ts\"))\n",
    "    .writeStream\n",
    "    .foreachBatch(start_events_write_to_cassandra)\n",
    "    #.format(\"console\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(processingTime=\"30 seconds\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ END events and WRITE to cassandra\n",
    "def end_events_write_to_cassandra(microbatch_input, epoch_id):\n",
    "    (microbatch_input\n",
    "     .write\n",
    "     .format(\"org.apache.spark.sql.cassandra\")\n",
    "     .option(\"keyspace\", \"session_events\")\n",
    "     .option(\"table\", \"api_completed_sessions\")\n",
    "     .mode(\"append\")\n",
    "     .save())\n",
    "    #microbatch_input.show(truncate=False)\n",
    "\n",
    "#START WRITE to cassandra\n",
    "strm_start_events_append_cassandra = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"delta\")\n",
    "    .load(source_dl_raw_path)\n",
    "    .where(F.col(\"event\")==\"end\")\n",
    "    .select(F.col(\"ts\").cast(DateType()).cast(StringType()).alias(\"event_date\"),\n",
    "            F.col(\"country\"),\n",
    "            F.lit(datetime.now(FinlandTimeZone).strftime('%Y-%m-%d %H:%M:%S')).cast(TimestampType()).alias(\"cs_insert_ts\"),\n",
    "            F.col(\"player_id\"),\n",
    "            F.col(\"session_id\"),\n",
    "            F.col(\"ts\"))\n",
    "    .writeStream\n",
    "    .foreachBatch(end_events_write_to_cassandra)\n",
    "    #.format(\"console\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(processingTime=\"30 seconds\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFO: listener to write into cassandra initiated\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
