{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Adrian J 2022-05\n",
    "import os\n",
    "import pytz\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from delta import * #to-do remove the wild import from delta\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DateType, StructType, StructField, StringType, TimestampType, IntegerType\n",
    "from etl_utils.table_schema import TableSchema\n",
    "from etl_utils.general_utils import persist_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recreate cassandra required keyspace and tables\n",
    "%run '/home/jovyan/work/init_script_cassandra.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get or create spark delta session\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local\")\n",
    "    .appName(\"p0_create_tables\")\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing empty session_event\n",
    "table_name = 'r_session_events'\n",
    "schema_root_path = '/home/jovyan/work/data_lake/raw/schemas'\n",
    "schema = 'assignment_data'\n",
    "dl_raw_path = f'/home/jovyan/work/data_lake/raw/{schema}/{table_name}/'\n",
    "partition_key = \"EVENT_DATE\"\n",
    "dl_insert_ts_column = \"DL_INSERT_TS\"\n",
    "sort_column = \"EVENT_DATE\"\n",
    "\n",
    "# Create an empty RDD with expected schema\n",
    "emp_RDD = spark.sparkContext.emptyRDD()\n",
    "columns = TableSchema(table_name, schema_root_path).load_schema_json()\n",
    "df_session_events_empty = spark.createDataFrame(data = emp_RDD, schema = columns)\n",
    "\n",
    "if os.path.exists(dl_raw_path):\n",
    "    print(f\"INFO: Table {table_name} exists... deleting\")\n",
    "    try:\n",
    "        shutil.rmtree(dl_raw_path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    persist_table(spark, df_session_events_empty, dl_raw_path, partition_key, table_name)\n",
    "else:\n",
    "    persist_table(spark, df_session_events_empty, dl_raw_path, partition_key, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing completed_session_event\n",
    "table_name = 'uc_delta_session_events'\n",
    "schema_root_path = '/home/jovyan/work/data_lake/use_case/schemas'\n",
    "schema = 'uc_assignment'\n",
    "dl_uc_path = f'/home/jovyan/work/data_lake/use_case/{schema}/{table_name}/'\n",
    "partition_key = \"EVENT_DATE\"\n",
    "dl_insert_ts_column = \"DL_INSERT_TS\"\n",
    "\n",
    "# Create an empty RDD with expected schema\n",
    "emp_RDD = spark.sparkContext.emptyRDD()\n",
    "columns = TableSchema(table_name, schema_root_path).load_schema_json()\n",
    "df_session_events_empty = spark.createDataFrame(data = emp_RDD, schema = columns)\n",
    "\n",
    "if os.path.exists(dl_uc_path):\n",
    "    print(f\"INFO: Table {table_name} exists... deleting\")\n",
    "    try:\n",
    "        shutil.rmtree(dl_uc_path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    persist_table(spark, df_session_events_empty, dl_uc_path, partition_key, table_name)\n",
    "else:\n",
    "    persist_table(spark, df_session_events_empty, dl_uc_path, partition_key, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
